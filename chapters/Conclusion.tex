\noindent The application of LDA, LSI, and BERT for topic modeling in the medical domain has proven to be effective in uncovering relevant terms and underlying themes from user queries. Each algorithm brings unique strengths: LDA and LSI offer interpretable topic structures and work well for general exploratory analysis, while BERT demonstrates superior contextual understanding, especially for complex or symptom based queries. Incorporating verb filtering in LDA slightly improved topic focus by reducing irrelevant terms. Overall, the results highlight that while traditional models still hold value in structured environments, transformer-based models like BERT are better suited for capturing semantic nuances and delivering more accurate, user-aligned outputs. This suggests a promising direction for enhancing search systems and clinical decision support tools with deep learning-based language models ` 